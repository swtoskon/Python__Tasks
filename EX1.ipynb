{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1 MLP KONSTANTAKOS SOTIRIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114137dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# fix random seed for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET HYPER-PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "momentumc=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show some of the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE  ARCHITECTURE OF OUR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,10)\n",
    "        nn.init.normal_(self.linear1.weight,mean=0,std=0.1)\n",
    "        nn.init.normal_(self.linear1.bias,mean=0,std=0.1)\n",
    "        #self.linear2 = nn.Linear(128,64)\n",
    "        self.linear2 = nn.Linear(10,10)\n",
    "        nn.init.normal_(self.linear2.weight,mean=0,std=0.1)\n",
    "        nn.init.normal_(self.linear2.bias,mean=0,std=0.1)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        #X = F.relu(self.linear2(X))\n",
    "        return F.log_softmax(self.linear2(X),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=momentumc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.4534797858057627\n",
      "Epoch 1 - Training loss: 0.3221931814281607\n",
      "Epoch 2 - Training loss: 0.3027522132666444\n",
      "Epoch 3 - Training loss: 0.28736647116000463\n",
      "Epoch 4 - Training loss: 0.2804354678974477\n",
      "Epoch 5 - Training loss: 0.2791657275093326\n",
      "Epoch 6 - Training loss: 0.27027229258198854\n",
      "Epoch 7 - Training loss: 0.2698177444273983\n",
      "Epoch 8 - Training loss: 0.2647132763643064\n",
      "Epoch 9 - Training loss: 0.2611175283813464\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss =0\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #foward pass  + backward + optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 92.69\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in test_loader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = model(img)\n",
    "\n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "            correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για να πετύχουμε πάνω απο 97 % accuracy έγιναν οι παρακάτω αλλαγές.Έγινε αλλαγή στην αρχιτεκτονική του νευρωνικού μας δικτύου.Πρόσθεσα ένα κρυφό επίπεδο που περιέχει 128 νευρώνες και ακολουθεί ένα ακόμα κρυφό επίπεδο που περιέχει 64 νευρώνες και τέλος το επίπεδο εξόδου και άλλαξα το lr σε 0.01.Οι συναρτήσεις ενεργοποίησης στα κρυφά επίπεδα είναι οι relu.Παρατηρούμε ότι από όλες τις υπέρ-παραμέτρους αυτό που επηρεάζει πιο πολύ ώστε να έχει καλύτερο accuracy το μοντέλο μας είναι του τι αρχιτεκτονική θα επιλέξουμε για το δίκτυο μας.Προσθέτοντας ένα ακόμα κρυφό επίπεδο βλέπουμε αρκετή διαφορά στο accuracy του μοντέλου μας ενώ όταν κάνουμε tune τις άλλες υπερ-παραμέτρους(κρατώντας τις άλλες με τις τιμές που τις είχαμε αρχικά) δεν παρατηρούμε μεγάλες βελτιώσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
